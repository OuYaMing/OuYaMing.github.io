---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

---
# ğŸ‘¤ About me
---
<!-- I am actively <span style="color:red;">looking for job opportunities</span>, including <span style="color:red;">paid postdoctoral, assistant/associate professor, and robotics algorithm researcher positions</span>. If you have any suitable openings, feel free to reach out to me at <span style="color:blue;">ouyaming2021@ia.ac.cn</span> or <span style="color:blue;">yamingo@andrew.cmu.edu</span>!-->

I'm an avid robotics enthusiast!ğŸ¤–ğŸ¤–ğŸ¤– Feel free to chat with me [ğŸ“§ğŸ“§ğŸ“§](mailto:ouyaming2021@ia.ac.cn).

I am **Yaming Ou** (**æ¬§äºšæ˜**), a **5th-year Ph.D.** student (5-year, supervised  by Prof. **[Zhou Chao](http://www.ia.cas.cn/rcdw/yjy/202406/t20240621_7194305.html)** and Assoc. Prof. **[Fan Junfeng](https://people.ucas.edu.cn/~fanjunfeng)**, affiliated with Prof. **[Tan Min](http://www.ia.cas.cn/rcdw/yjy/202404/t20240422_7129785.html)**) with the Laboratory of Cognition and Decision Intelligence for Complex Systems (**[C<sup>2</sup>DL](http://www.ia.cas.cn/jgsz/kyxt/fzxtrz/?LMCL=vN3cUI&LMCL=Y9slHN)**), Institute of Automation, Chinese Academy of Sciences (**[CASIA](http://www.ia.cas.cn/)**), Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences (**[UCAS](https://www.ucas.edu.cn/)**), Beijing 100049, China. 

Now, I am currently pursuing in **joint Ph.D.** program under the supervision of Prof. **[Howie Choset](https://scholar.google.com/citations?hl=zh-CN&user=4fvo61oAAAAJ)** at Robotics Institute, Carnegie Mellon University (**[CMU RI](https://www.ri.cmu.edu/)**), and conducting robot control and navigation research at the **[Biorobotics Lab](https://www.ri.cmu.edu/robotics-groups/biorobotics/)** from March 2025 to March 2026.

I graduated from the School of Automation at Southeast University (**[SEU, 985](https://www.seu.edu.cn/)**) with a Bachelor's degree in Robotics Engineering, [School of Automation](https://automation.seu.edu.cn/) (**Rank: 2/34ï¼ŒOutstanding Graduate Award**).

My research interests includeï¼š**SLAM**, **autonomous robot navigation**, **multi-modal perception**.


---
# ğŸ”¥ News
---
<!-- 
- *2024.07.26*: &nbsp; ğŸ˜ŠğŸ˜ŠA SLAM-related paper accepted by TIE!
- *2024.06.14*: &nbsp; Invited by TIV to review a paper related to autonomous drivingğŸ‰ğŸ‰
- *2024.05.30*: &nbsp; ğŸ‰ğŸ˜ŠRecognized as an outstanding student leader of UCAS
- *2024.03.21*: &nbsp; Publish a paper in TSMC!ğŸ˜ŠğŸ˜Š
- *2023.11.25*: &nbsp;ğŸ‰A paper accepted by TIV!ğŸ˜Š
- *2023.10.06*: &nbsp; A paper accepted by TII!ğŸ‰
- *2021.06.15*: &nbsp;ğŸ‰ğŸ‰Invited by IEEE Sensor to review a paper related to camera-imu calibrationğŸ˜Š
- *2023.03.27*: &nbsp;ğŸ˜Š Publish a paper in TIM!ğŸ˜Š
- *2023.03.09*: &nbsp;ğŸ‰ Successfully selected for the PHD experimental class of CASIA!ğŸ‰
- *2021.07.29*: &nbsp;ğŸ˜Š Participation in the China Control Conference in Shanghai,China!ğŸ‰ğŸ‰
- *2021.06.31*: &nbsp;ğŸ‰ğŸ‰ Successfully graduate from SEU and go to Beijing to start PHD!ğŸ˜Š-->
<div style="max-height: 150px; overflow-y: auto; font-family: 'Times New Roman', Times, serif; font-size: 11.5pt;">

2025.10.05: &nbsp; ğŸ‰A paper accepted by TMech!ğŸ˜Šï¼
<br>
2025.09.29: &nbsp; Invited by ICRA 2026 to review two papers related to robot navigation and mappingï¼
<br>
2025.08.15: &nbsp; Invited by TRO to review a paper related to underwater robot localizationï¼ğŸ˜Š
<br>
2025.04.28: &nbsp; Submitted a paper to TRO!ğŸ‰ğŸ™
<br>
2025.03.15: &nbsp; Arrived in Pittsburgh and starting a new chapter at CMU!ğŸ‰ğŸ‰
<br>
2024.12.25: &nbsp; My paper surpasses 100 citations in <a href="https://scholar.google.com/citations?user=JD82F9kAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>!ğŸ˜ŠğŸ˜Š
<br>
2024.12.25: &nbsp; Selected for the <a href="https://www.ucas.ac.cn/tz/f1f9453a721644158e3838383784e97a.htm" target="_blank">UCAS PhD International Cooperation Training Program</a> (one spot per institute)ï¼ğŸ‰ğŸ‰
<br>
2024.11.20: &nbsp; Invited by TIE to review a paper related to semantic localizationï¼ğŸ‰ğŸ‰  
<br>
2024.11.20: &nbsp; Awarded China PhD National Scholarshipï¼ğŸ‰ğŸ˜Š
<br>
2024.11.16: &nbsp; A participating paper accepted by Bioinspiration & Biomimeticsï¼ğŸ˜Š
<br>
2024.07.26: &nbsp; ğŸ˜ŠğŸ˜ŠA SLAM-related paper accepted by TIE!
<br>
2024.06.14: &nbsp; Invited by TIV to review a paper related to autonomous drivingï¼ğŸ‰ğŸ‰  
<br>
2024.05.30: &nbsp; ğŸ‰ğŸ˜ŠRecognized as an outstanding student leader of UCAS  ï¼
<br>
2024.03.21: &nbsp; Publish a paper in TSMC!ğŸ˜ŠğŸ˜Š  
<br>
2023.11.25: &nbsp;ğŸ‰A paper accepted by TIV!ğŸ˜Š  
<br>
2023.10.06: &nbsp; A paper accepted by TII!ğŸ‰  
<br>
2023.06.15: &nbsp;ğŸ‰ğŸ‰Invited by IEEE Sensor to review a paper related to camera-imu calibrationğŸ˜Š  
<br>
2023.03.27: &nbsp;ğŸ˜Š Publish a paper in TIM!ğŸ˜Š  
<br>
2023.03.09: &nbsp;ğŸ‰ Successfully selected for the PHD experimental class of CASIA!ğŸ‰  
<br>
2021.07.29: &nbsp;ğŸ˜Š Participation in the China Control Conference in Shanghai,China!ğŸ‰ğŸ‰  
<br>
2021.06.31: &nbsp;ğŸ‰ğŸ‰ Successfully graduate from SEU and go to Beijing to start PHD!ğŸ˜Š  

</div>


---
# ğŸ“– Educations
---
- *2025.03 - 2026.03(expected)*:&nbsp; Robotics Institute, Carnegie Mellon University (**Joint Ph.D.**)
- *2021.09 - 2026.06(expected)*:&nbsp; Institute of Automation, Chinese Academy of Sciences (**Ph.D.**)
- *2021.09 - 2022.06*:&nbsp; School of Artificial Intelligence, University of Chinese Academy of Sciences (**Ph.D.**)
- *2018.06 - 2021.06*:&nbsp; Department of Robotics Engineering, School of Automation, Southeast University (**B.E.**)
- *2017.09 - 2018.06*:&nbsp; School of Materials Science and Engineering, Southeast University (**B.E.**)

---
# ğŸ“ Publications 
---
For a more detailed presentation, see [Publications](https://ouyaming.github.io/publications/).

(**<sup>*</sup>** indicates corresponding author)

<ol>
  <li><b>Y. Ou</b>, J. Fan, et al. "Hybrid-VINS: Underwater Tightly-Coupled Hybrid Visual Inertial Dense SLAM for AUV," in IEEE Transactions on Industrial Electronics, 2024. (<i>SCI, JCR Q1, ä¸­ç§‘é™¢ä¸€åŒºTopï¼ŒIF=7.5</i>)</li>

  <li><b>Y. Ou</b> et al., "Structured Light-Based Underwater Collision-Free Navigation and Dense Mapping System for Refined Exploration in Unknown Dark Environments," in IEEE Transactions on Systems, Man, and Cybernetics: Systems, doi: 10.1109/TSMC.2024.3370917. (<i>SCI, JCR Q1, ä¸­ç§‘é™¢ä¸€åŒºTop, IF=8.7</i>)</li>

  <li><b>Y. Ou</b>, J. Fan, C. Zhou, L. Cheng and M. Tan, "Water-MBSL: Underwater Movable Binocular Structured Light-Based High-Precision Dense Reconstruction Framework," in IEEE Transactions on Industrial Informatics, vol. 20, no. 4, pp. 6142-6154, April 2024, doi: 10.1109/TII.2023.3342899. (<i>SCI, JCR Q1, ä¸­ç§‘é™¢ä¸€åŒºTop, IF=12.3</i>)</li>

  <li><b>Y. Ou</b>, J. Fan, C. Zhou, S. Tian, L. Cheng and M. Tan, "Binocular Structured Light 3-D Reconstruction System for Low-Light Underwater Environments: Design, Modeling, and Laser-Based Calibration," in IEEE Transactions on Instrumentation and Measurement, vol. 72, pp. 1-14, 2023, Art no. 5010314, doi: 10.1109/TIM.2023.3261941. (<i>SCI, JCR Q1, ä¸­ç§‘é™¢äºŒåŒºTop, IF=5.6</i>)</li>

  <li>J. Fan, <b>Y. Ou<sup>*</sup></b>, X. Li, C. Zhou and Z. Hou, "Structured light vision based pipeline tracking and 3D reconstruction method for underwater vehicle," in IEEE Transactions on Intelligent Vehicles, doi: 10.1109/TIV.2023.3340737. (<i>corresponding author, SCI, JCR Q1, ä¸­ç§‘é™¢ä¸€åŒºï¼ŒIF=8.2</i>)</li>

  <li><b>Y. Ou</b>, Z. Zhang, C. Zhou and B. Zhou, "Data Calibration Algorithm for Artificial Lateral Line Sensor of Robotic Fish on Improved LSTM," 2021 40th Chinese Control Conference (CCC), Shanghai, China, 2021, pp. 4308-4314, doi: 10.23919/CCC52363.2021.9549820. (<i>EI</i>)</li>
</ol>


---
# ğŸ›¡ï¸ Patents 
---
1. Zhou C, **Ou Y**, Fan J, et al, Underwater Mobile Dense Mapping Platform and Mapping Method Based on Binocular Structured Light. Chinese Patent, CN117893675A.
2. Zhou C, **Ou Y**, Fan J, et al, A Simultaneous Localization System and Method for Underwater Robots. Chinese Patent, KHP2411116437.0.
3. Zhang Z, Zhou C, Fan J, **Ou Y**, Bionic Lateral Line Sensor. Chinese Patent, CN114624461B.
4. Zhang Z, Zhou C, Fan J, ..., **Ou Y**. Calibration Model Training Method, Device and System, Electronic Equipment and Storage Medium. Chinese Patent, CN117634641A.

---
# ğŸ† Honors & Awards
---
- *2024*:&nbsp; ğŸ“œSelected for the PhD International Cooperation Program of UCAS (**one spot per institute**)
- *2024*:&nbsp; ğŸ“œChina PhD National Scholarship (**3%, 3W RMB award**)
- *2024*:&nbsp; ğŸ“œOutstanding Student Leader Award of UCAS (**top 2%**)
- *2023*:&nbsp; ğŸ“œSelected for the PHD experimental class of CASIA (**8/276, 5W RMB scholarships each year**)
- *2022*:&nbsp; ğŸ¥‡China ICV Algorithms Challenge Competition(**1st place, 2W RMB award**)
- *2022*:&nbsp; ğŸ“œThree Good Students Award of UCAS (**top 10%**)
- *2021*:&nbsp; ğŸ†Data Application Innovation and Entrepreneurship Competition (**merit award, 9/453**)
- *2021*:&nbsp; ğŸ“œOutstanding Graduate Student Award of Southeast University (**top 3%**)
- *2020*:&nbsp; ğŸ¥ˆNational College Students Intelligent Vehicle Competition (**national 2nd prize**)
- *2020*:&nbsp; ğŸ“œChina National Inspiration Scholarship (**3.22%**)
- *2019*:&nbsp; ğŸ¥‡RoboCup Robotics World Cup (China Region) (**national 1st prize**)
- *2019*:&nbsp; ğŸ¥ˆNational College Students Electronic Design Competition (**national 2nd prize**)
- *2019*:&nbsp; ğŸ¥‡The 10th Robot Competition of Jiangsu Province (**provincial 1st prize**)
- *2019*:&nbsp; ğŸ“œThree Good Students Award of Southeast University (**top 10%**)
- *2018*:&nbsp; ğŸ¥‡The 9th Robot Competition of Jiangsu Province (**provincial 1st prize**)
- *2016*:&nbsp; ğŸ¥ˆHigh School Mathematics Olympiad Competition, Anhui Province (**provincial 2nd prize**)

---
# ğŸ› ï¸ Projects & Competitions
---
For a more detailed presentation, see [Publications](https://ouyaming.github.io/publications/) and [Projects](https://ouyaming.github.io/projects/).

<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TMech -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/black_vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="" target="_blank">
          <papertitle>PL-VAP: A Tightly Coupled Self-Localization Framework for Underwater Robots Using Point-Line Features and Visual-Acoustic-Pressure Sensor Fusion</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Submitted in <em> IEEE/ASME Transactions on Mechatronics</em>, 2025</span>
        <br>
        <p>Will come later.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">SLAM</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Multi-sensor Fusion</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>


<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TIE -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/2024-TIE-vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="" target="_blank">
          <papertitle>Hybrid-VINS: Underwater Tightly-Coupled Hybrid Visual Inertial Dense SLAM for AUV</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Industrial Electronics</em>, 2024</span>
        <br>
        <!--  -->
        <p>An underwater tightly-coupled hybrid visual inertial dense SLAM framework, named Hybrid-VINS, is proposed, which is the first underwater SLAM system to utilize active vision information to assist passive vision.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">SLAM</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Camera-IMU Fusion</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/2024-TIE-vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TSMC -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/2024-03-18-TSMC_vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2024-03-18-TSMC" target="_blank">
          <papertitle>Structured Light-Based Underwater Collision-Free Navigation and Dense Mapping System for Refined Exploration in Unknown Dark Environments</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Systems, Man, and Cybernetics: Systems</em>, 2024</span>
        <br>
        <!--  -->
        <p>A more adaptable 3D dense mapping robotic system based on self-designed scanning BSL, named ROVScanner, is developed for refined exploration, where the on-board design allows for autonomous mobility and operational capabilities.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Navigation</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Obstacle Avoidance</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2024-03-18-TSMC.pdf" target="_blank">[Paper]</a>
          <a href="https://ouyaming.github.io/vedio/2024-03-18-TSMC_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TII -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/2023-12-29-TII_vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2023-12-29-TII" target="_blank">
          <papertitle>Water-MBSL: Underwater Movable Binocular Structured Light-Based High-Precision Dense Reconstruction Framework</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Industrial Informatics</em>, 2023</span>
        <br>
        <!--  -->
        <p>An SSLSLS-based underwater movable high-precision dense reconstruction framework, named Water-movable binocular structured light (MBSL), is proposed, which takes into account both motion distortion and point cloud registration.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Dense Mapping</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Motion Reconstruction</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2023-12-29-TII.pdf" target="_blank">[Paper]</a>
          <a href="https://ouyaming.github.io/vedio/2023-12-29-TII_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<head>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</head>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TIM -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 2s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="3"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/1.png" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/2.png" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/3.png" class="d-block w-100" alt="Image 3" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/8.png" class="d-block w-100" alt="Image 4" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2023-03-27-TIM" target="_blank">
          <papertitle>Binocular Structured Light 3-D Reconstruction System for Low-light Underwater Environments: Design, Modeling, and Laser-based Calibration</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Instrumentation and Measurement</em>, 2023</span>
        <br>
        <!--  -->
        <p>An underwater binocular structured light 3-D reconstruction system with the scanning laser is designed to realize the static high-precision scanning reconstruction of the low-light scene, which is suitable for underwater robot application.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">3D Reconstruction</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Active Vision</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2023-03-27-TIM.pdf" target="_blank">[Paper]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TIV -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/2023-12-08-TIV_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2023-12-08-TIV" target="_blank">
          <papertitle>Structured Light Vision-Based Pipeline Tracking and 3D Reconstruction Method for Underwater Vehicle</papertitle>
        </a >
        <br>
        Junfeng Fan, <strong>Yaming Ou*</strong>,  Xuan Li, etc. (corresponding author)
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Intelligent Vehicles</em>, 2023</span>
        <br>
        <!--  -->
        <p>A novel underwater pipeline positioning method based on dual-line laser SLV is proposed, which can simultaneously obtain the lateral deviation, height deviation and heading deviation of underwater vehicle and underwater pipeline under weak light water environment, providing the basis for underwater pipeline tracking.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">3D Reconstruction</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Pipeline Tracking</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2023-12-08-TIV.pdf" target="_blank">[Paper]</a>
          <a href="https://ouyaming.github.io/vedio/2023-12-08-TIV_vedio.mp4" target="_blank">[Vedio]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- CCC -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 2s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="3"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="4"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/1.png" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/2.png" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/3.png" class="d-block w-100" alt="Image 3" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/4.png" class="d-block w-100" alt="Image 4" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/5.png" class="d-block w-100" alt="Image 4" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2021-07-26-CCC" target="_blank">
          <papertitle>Data Calibration Algorithm for Artificial Lateral Line Sensor of Robotic Fish on Improved LSTM</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Zhuoliang Zhang, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>2021 40th Chinese Control Conference (CCC)</em>, 2023</span>
        <br>
        <!--  -->
        <p>A cantilever artificial lateral line (ALL) sensor based on piezoresistive effect was developed by imitating the "SNs" cell structure of real fish to realize underwater speed measurement.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Speed Measurement</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Biomimetic Sensor</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2021-07-26-CCC.pdf" target="_blank">[Paper]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- ç™¾åº¦AIæ™ºèƒ½è½¦ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_AI_smart_car_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Self-Driving Vehicle</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Intelligent Vehicle Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        &nbsp;&nbsp;
        <strong>Sponsor</strong>
        <em><a href="https://www.baidu.com/" target="_blank">Baidu</a></em>
        <br>
        <!--  -->
        <p>Vehicle autonomous driving according to different traffic signs. In addition, based on the target detection algorithm YoloV4-Tiny, the deployment of deep learning algorithms on an embedded development board is realized and guarantees the safe form of the vehicle in the lane.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Detection</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_AI_smart_car_vedio.mp4" target="_blank">[Video]</a>
          <a href="https://ouyaming.github.io/files/project_AI_smart_car_pdf.pdf" target="_blank">[Report]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- LKA -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_LKA_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Lane Keeping Assist (LKA) Control Based on the LQR Controller</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>China ICV Algorithms Challenge</em>
        <br>
        <strong>Award</strong> <em>First Prize</em>
        &nbsp;&nbsp;
        <strong>Sponsor</strong>
        <em><a href="https://www.china-icv.cn/" target="_blank">China-ICV</a></em>
        <br>
        <p>This is about lateral control technology in autonomous driving. Our algorithm enables lateral lane keeping and speed keeping for cars in different scenarios.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">LQR Control</span>
          &nbsp;&nbsp;
          <br>
          &nbsp;&nbsp;
          <br>
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_LKA_vedio.mp4" target="_blank">[Video]</a>
          <a href="https://ouyaming.github.io/files/project_LKA_pdf.pdf" target="_blank">[Report]</a>
          <a href="https://github.com/Zhihaibi/Lateral_control" target="_blank">[Code]</a>        
        </p>
      </td>
    </tr>
  </tbody>
</table>
<head>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</head>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- ç”µèµ›ï¼šåŠ¨æ€æ— çº¿èŠ‚èƒ½å……ç”µå°è½¦ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 2s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/electronic_design/1.png" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/electronic_design/2.jpg" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Dynamic Wireless Energy-saving Charging Vehicle</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This work is based on TI Msp430F5529 to form a dynamic wireless energy-saving charging cart system. </p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Dynamic Charging</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PID Controller</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/project_electronic_design_pdf.pdf" target="_blank">[Report]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- æ—‹è½¬å€’ç«‹æ‘† -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_secondary_rotary_inverted_pendulum_system_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Rotary Inverted Pendulum System</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This is one of the training programs for electronic design competitions. Through the coordination of stepper motors and angle sensors, and based on a serial PID control algorithm, the system can initiate and maintain an inverted pendulum state. What an interesting experiment!</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Inverted Pendulum</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PID Controller</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_secondary_rotary_inverted_pendulum_system_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- æ— çº¿åŠ¨æ€å……ç”µå¾ªè¿¹å°è½¦ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_wireless_dynamic_charging_tracking_smart_car_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Wireless Dynamic Charging Tracking Smart Car</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This is one of the training programs for electronic design competitions. The smart car realizes dynamic charging during movement through a wireless charging module and has the ability to track the rapid movement of wire lines.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Dynamic Charging</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_wireless_dynamic_charging_tracking_smart_car_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- åŒçº¿æ‚¬æŒ‚ç³»ç»Ÿ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_dual_wire_suspension_control_system_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Dual Wire Drive Control System</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This is one of the training programs for electronic design competitions. The system's driving unit consists of two soft thin strings. The movement in the 2D plane is achieved by controlling the extension and retraction of the two strings independently using stepper motors, allowing the system to draw patterns such as hearts.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Wire Drive</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PID Controller</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_dual_wire_suspension_control_system_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- Turtlebot SLAM -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_turtlebot_slam_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Multi-point Cruise Turtlebot Robot</papertitle>
        </a >
        <p>By deploying the cartographer 2D laser SLAM algorithm on the turtlebot robot, combined with an A* navigation algorithm and a PID motion control algorithm. The robot can realize multi-point cruise operations.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">SLAM</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Navigation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_turtlebot_slam_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- äº”å­æ£‹ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_robotarm_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Human-machine Game of Gomoku with ABB 6-Axis Robotic Arm</papertitle>
        </a >
        <p>Using the RGBD camera (on the hand) to identify gomoku, planning with the robot arm to complete the human-computer game.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Human-machine Game</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Hand-eye Calibration</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_robotarm_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- è¡Œææ¬è¿æœºå™¨äºº -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_baggage_handling robot_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Luggage Recognition Interactive Robot</papertitle>
        </a >
        <p> Identify the luggage bag and its owner, take the luggage and follow the owner.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Human-robot Interaction</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_baggage_handling robot_vedio.mp4" target="_blank">[Video]</a>
          <a href="https://github.com/OuYaMing/Curriculum-Baggage-Handling-Robot" target="_blank">[Code]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- è¶…å¸‚åˆ†æ‹£æœºå™¨äºº -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_supermarket_automatic_sorting_robot_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Webots Simulation: Supermarket Automatic Sorting Robot</papertitle>
        </a >
        <p> This is the working scenario of a supermarket sorting mobile robot built in the Webots simulation environment. The robot can identify specific items and place them on the corresponding supermarket shelves.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PathPlanning</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Webots Simulation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_supermarket_automatic_sorting_robot_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- Webotsæ— äººé©¾é©¶ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_driverless_simulation_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Webots Simulation: Autonomous Driving</papertitle>
        </a >
        <p> This is a self-driving highway simulation system built in the Webots simulation environment. With the obstacle detection algorithm, obstacle avoidance strategy and road tracking control algorithm, the car can safely avoid other obstacles and move forward at a high speed.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Obstacle Avoidance</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Webots Simulation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_driverless_simulation_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- è¡£ç‰©åˆ†æ‹£ç³»ç»Ÿ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
          <img src="https://ouyaming.github.io/vedio/project_automatic_clothes_sorting_system_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Clothes Automatic Sorting System</papertitle>
        </a >
        <p>Sorting clothes into different containers according to the color using robot arms.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Detection</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Matlab Simulation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_automatic_clothes_sorting_system_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- æ ‘è“æ´¾æ™ºèƒ½è½¦ -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_raspberry_pi_smart _car_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Raspberry Pi Smart Car</papertitle>
        </a >
        <p> The main control board of the smart car is a Raspberry Pi 2B+, which uses a camera to identify the red lane lines and track them, and identifies crosswalks to slow down and simulate daily traffic road scenes.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Detection</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_raspberry_pi_smart _car_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<head>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</head>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- é¤ç›˜åˆ†å‰² -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 1s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/Plate_detection/1.gif" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/Plate_detection/2.png" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/Plate_detection/3.jpg" class="d-block w-100" alt="Image 3" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Plate detection through image processing</papertitle>
        </a >
        <p>Image processing techniques were used to extract the location of the dinner plate in the picture, thus assisting the robot to complete the automatic meal-punching operation.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Image Processing</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Segmentation</span>
        </p>
      </td>
    </tr>
  </tbody>
</table>

&nbsp;  
&nbsp;  
<table style="width:100%;max-width:601px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=FrEzGBBnkb2X2rV9OFHx8YYKNq1Th4qkAMalbwI5cTg"></script>
</tbody></table>


