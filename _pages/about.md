---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

---
# 👤 About me
---
I am **Yaming Ou** (**欧亚明**), a **3rd-year Ph.D.** student with the Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences (**[CASIA](http://www.ia.cas.cn/)**), Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences (**[UCAS](https://www.ucas.edu.cn/)**), Beijing 100049, China. 

I graduated from the School of Automation at Southeast University (**[SEU, 985](https://www.seu.edu.cn/)**) with a Bachelor's degree in Robotics Engineering (**GPA Rank: 2/34**).

My research interests include：underwater 3D vision, multi-sensor fusion SLAM, autonomous robot navigation.


---
# 🔥 News
---
<!-- 
- *2024.06.14*: &nbsp; Invited by TIV to review a paper related to autonomous driving🎉🎉
- *2024.05.30*: &nbsp; 🎉😊Recognized as an outstanding student leader of UCAS
- *2024.03.21*: &nbsp; Publish a paper in TSMC!😊😊
- *2023.11.25*: &nbsp;🎉A paper accepted by TIV!😊
- *2023.10.06*: &nbsp; A paper accepted by TII!🎉
- *2021.06.15*: &nbsp;🎉🎉Invited by IEEE Sensor to review a paper related to camera-imu calibration😊
- *2023.03.27*: &nbsp;😊 Publish a paper in TIM!😊
- *2023.03.09*: &nbsp;🎉 Successfully selected for the PHD experimental class of CASIA!🎉
- *2021.07.29*: &nbsp;😊 Participation in the China Control Conference in Shanghai,China!🎉🎉
- *2021.06.31*: &nbsp;🎉🎉 Successfully graduate from SEU and go to Beijing to start PHD!😊-->
<div style="max-height: 150px; overflow-y: auto; font-family: 'Times New Roman', Times, serif; font-size: 11.5pt;">

2024.06.14: &nbsp; Invited by TIV to review a paper related to autonomous driving🎉🎉  
<br>
2024.05.30: &nbsp; 🎉😊Recognized as an outstanding student leader of UCAS  
<br>
2024.03.21: &nbsp; Publish a paper in TSMC!😊😊  
<br>
2023.11.25: &nbsp;🎉A paper accepted by TIV!😊  
<br>
2023.10.06: &nbsp; A paper accepted by TII!🎉  
<br>
2021.06.15: &nbsp;🎉🎉Invited by IEEE Sensor to review a paper related to camera-imu calibration😊  
<br>
2023.03.27: &nbsp;😊 Publish a paper in TIM!😊  
<br>
2023.03.09: &nbsp;🎉 Successfully selected for the PHD experimental class of CASIA!🎉  
<br>
2021.07.29: &nbsp;😊 Participation in the China Control Conference in Shanghai,China!🎉🎉  
<br>
2021.06.31: &nbsp;🎉🎉 Successfully graduate from SEU and go to Beijing to start PHD!😊  

</div>


---
# 📖 Educations
---
- *2021.09 - 2026.06(expected)*:&nbsp; Institute of Automation, Chinese Academy of Sciences (**Ph.D.**)
- *2021.09 - 2022.06*:&nbsp; School of Artificial Intelligence, University of Chinese Academy of Sciences (**Ph.D.**)
- *2018.06 - 2021.06*:&nbsp; Department of Robotics Engineering, School of Automation, Southeast University (**B.E.**)
- *2017.09 - 2018.06*:&nbsp; School of Materials Science and Engineering, Southeast University (**B.E.**)

---
# 📝 Publications 
---
For a more detailed presentation, see [Publications](https://ouyaming.github.io/publications/).

(**<sup>*</sup>** indicates corresponding author)
1. **Y. Ou** et al., "Structured Light-Based Underwater Collision-Free Navigation and Dense Mapping System for Refined Exploration in Unknown Dark Environments," in IEEE Transactions on Systems, Man, and Cybernetics: Systems, doi: 10.1109/TSMC.2024.3370917. (**SCI, JCR Q1, 中科院一区Top, IF=8.7**)
2. **Y. Ou**, J. Fan, C. Zhou, L. Cheng and M. Tan, "Water-MBSL: Underwater Movable Binocular Structured Light-Based High-Precision Dense Reconstruction Framework," in IEEE Transactions on Industrial Informatics, vol. 20, no. 4, pp. 6142-6154, April 2024, doi: 10.1109/TII.2023.3342899. (**SCI, JCR Q1, 中科院一区Top, IF=12.3**)
3. **Y. Ou**, J. Fan, C. Zhou, S. Tian, L. Cheng and M. Tan, "Binocular Structured Light 3-D Reconstruction System for Low-Light Underwater Environments: Design, Modeling, and Laser-Based Calibration," in IEEE Transactions on Instrumentation and Measurement, vol. 72, pp. 1-14, 2023, Art no. 5010314, doi: 10.1109/TIM.2023.3261941. (**SCI, JCR Q1, 中科院二区Top, IF=5.6**)
4. J. Fan, **Y. Ou<sup>*</sup>**, X. Li, C. Zhou and Z. Hou, "Structured light vision based pipeline tracking and 3D reconstruction method for underwater vehicle," in IEEE Transactions on Intelligent Vehicles, doi: 10.1109/TIV.2023.3340737. (**corresponding author, SCI, JCR Q1, 中科院一区，IF=8.2**)
5. **Y. Ou**, Z. Zhang, C. Zhou and B. Zhou, "Data Calibration Algorithm for Artificial Lateral Line Sensor of Robotic Fish on Improved LSTM," 2021 40th Chinese Control Conference (CCC), Shanghai, China, 2021, pp. 4308-4314, doi: 10.23919/CCC52363.2021.9549820. (**EI**)
6. **Y. Ou**, J. Fan, et al. "Hybrid-VINS: Underwater Tightly-Coupled Hybrid Visual Inertial Dense SLAM for AUV," in IEEE Transactions on Industrial Electronics, 2024. (**Major Revision, SCI, JCR Q1, 中科院一区，IF=7.6**)

---
# 🛡️ Patents 
---
1. Zhou C, **Ou Y**, Fan J, et al, Underwater Mobile Dense Mapping Platform and Mapping Method Based on Binocular Structured Light. Chinese Patent, CN117893675A.
2. Zhou C, **Ou Y**, Fan J, et al, A Simultaneous Localization System and Method for Underwater Robots. Chinese Patent, KHP2411116437.0.
3. Zhang Z, Zhou C, Fan J, **Ou Y**, Bionic Lateral Line Sensor. Chinese Patent, CN114624461B.
4. Zhang Z, Zhou C, Fan J, ..., **Ou Y**. Calibration Model Training Method, Device and System, Electronic Equipment and Storage Medium. Chinese Patent, CN117634641A.

---
# 🏆 Honors & Awards
---
- *2024*:&nbsp; 📜Outstanding Student Leader Award of UCAS (**top 2%**)
- *2023*:&nbsp; 📜Selected for the PHD experimental class of CASIA (**8/276, 5W RMB scholarships each year**)
- *2022*:&nbsp; 🥇China ICV Algorithms Challenge Competition(**1st place, 2W RMB award**)
- *2022*:&nbsp; 📜Three Good Students Award of UCAS (**top 10%**)
- *2021*:&nbsp; 🏆Data Application Innovation and Entrepreneurship Competition (**merit award, 9/453**)
- *2021*:&nbsp; 📜Outstanding Graduate Student Award of Southeast University (**top 3%**)
- *2020*:&nbsp; 🥈National College Students Intelligent Vehicle Competition (**national 2nd prize**)
- *2020*:&nbsp; 📜China National Inspiration Scholarship (**3.22%**)
- *2019*:&nbsp; 🥇RoboCup Robotics World Cup (China Region) (**national 1st prize**)
- *2019*:&nbsp; 🥈National College Students Electronic Design Competition (**national 2nd prize**)
- *2019*:&nbsp; 🥇The 10th Robot Competition of Jiangsu Province (**provincial 1st prize**)
- *2019*:&nbsp; 📜Three Good Students Award of Southeast University (**top 10%**)
- *2018*:&nbsp; 🥇The 9th Robot Competition of Jiangsu Province (**provincial 1st prize**)
- *2016*:&nbsp; 🥈High School Mathematics Olympiad Competition, Anhui Province (**provincial 2nd prize**)

---
# 🛠️ Projects & Competitions
---
For a more detailed presentation, see [Publications](https://ouyaming.github.io/publications/) and [Projects](https://ouyaming.github.io/projects/).
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TIE -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/2024-TIE-vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="" target="_blank">
          <papertitle>Hybrid-VINS: Underwater Tightly-Coupled Hybrid Visual Inertial Dense SLAM for AUV</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Submitted in <em>IEEE Transactions on Industrial Electronics</em>, 2024</span>
        <br>
        <!--  -->
        <p>An underwater tightly-coupled hybrid visual inertial dense SLAM framework, named Hybrid-VINS, is proposed, which is the first underwater SLAM system to utilize active vision information to assist passive vision.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">SLAM</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Camera-IMU Fusion</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/2024-TIE-vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TSMC -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/2024-03-18-TSMC_vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2024-03-18-TSMC" target="_blank">
          <papertitle>Structured Light-Based Underwater Collision-Free Navigation and Dense Mapping System for Refined Exploration in Unknown Dark Environments</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Systems, Man, and Cybernetics: Systems</em>, 2024</span>
        <br>
        <!--  -->
        <p>A more adaptable 3D dense mapping robotic system based on self-designed scanning BSL, named ROVScanner, is developed for refined exploration, where the on-board design allows for autonomous mobility and operational capabilities.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Navigation</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Obstacle Avoidance</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2024-03-18-TSMC.pdf" target="_blank">[Paper]</a>
          <a href="https://ouyaming.github.io/vedio/2024-03-18-TSMC_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TII -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <p style="text-align:center">
          <video style="width:100%;height:auto;" controls="controls">
            <source src="https://ouyaming.github.io/vedio/2023-12-29-TII_vedio.mp4" type="video/mp4" />
          </video>
        </p>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2023-12-29-TII" target="_blank">
          <papertitle>Water-MBSL: Underwater Movable Binocular Structured Light-Based High-Precision Dense Reconstruction Framework</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Industrial Informatics</em>, 2023</span>
        <br>
        <!--  -->
        <p>An SSLSLS-based underwater movable high-precision dense reconstruction framework, named Water-movable binocular structured light (MBSL), is proposed, which takes into account both motion distortion and point cloud registration.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Dense Mapping</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Motion Reconstruction</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2023-12-29-TII.pdf" target="_blank">[Paper]</a>
          <a href="https://ouyaming.github.io/vedio/2023-12-29-TII_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<head>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</head>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TIM -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 2s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="3"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/1.png" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/2.png" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/3.png" class="d-block w-100" alt="Image 3" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2023-03-27-TIM/8.png" class="d-block w-100" alt="Image 4" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2023-03-27-TIM" target="_blank">
          <papertitle>Binocular Structured Light 3-D Reconstruction System for Low-light Underwater Environments: Design, Modeling, and Laser-based Calibration</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Junfeng Fan, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Instrumentation and Measurement</em>, 2023</span>
        <br>
        <!--  -->
        <p>An underwater binocular structured light 3-D reconstruction system with the scanning laser is designed to realize the static high-precision scanning reconstruction of the low-light scene, which is suitable for underwater robot application.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">3D Reconstruction</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Active Vision</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2023-03-27-TIM.pdf" target="_blank">[Paper]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- TIV -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/images/500x300.png" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2023-03-27-TIM" target="_blank">
          <papertitle>Structured Light Vision-Based Pipeline Tracking and 3D Reconstruction Method for Underwater Vehicle</papertitle>
        </a >
        <br>
        Junfeng Fan, <strong>Yaming Ou*</strong>,  Xuan Li, etc. (corresponding author)
        <br>
        <span style="font-size: 10pt;">Published in <em>IEEE Transactions on Intelligent Vehicles</em>, 2023</span>
        <br>
        <!--  -->
        <p>A novel underwater pipeline positioning method based on dual-line laser SLV is proposed, which can simultaneously obtain the lateral deviation, height deviation and heading deviation of underwater vehicle and underwater pipeline under weak light water environment, providing the basis for underwater pipeline tracking.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">3D Reconstruction</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Pipeline Tracking</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2023-12-08-TIV.pdf" target="_blank">[Paper]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- CCC -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 2s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="3"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="4"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/1.png" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/2.png" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/3.png" class="d-block w-100" alt="Image 3" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/4.png" class="d-block w-100" alt="Image 4" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/2021-07-26-CCC/5.png" class="d-block w-100" alt="Image 4" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/publication/2021-07-26-CCC" target="_blank">
          <papertitle>Data Calibration Algorithm for Artificial Lateral Line Sensor of Robotic Fish on Improved LSTM</papertitle>
        </a >
        <br>
        <strong>Yaming Ou</strong>, Zhuoliang Zhang, Chao Zhou, etc.
        <br>
        <span style="font-size: 10pt;">Published in <em>2021 40th Chinese Control Conference (CCC)</em>, 2023</span>
        <br>
        <!--  -->
        <p>A cantilever artificial lateral line (ALL) sensor based on piezoresistive effect was developed by imitating the "SNs" cell structure of real fish to realize underwater speed measurement.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Speed Measurement</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Biomimetic Sensor</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/2021-07-26-CCC.pdf" target="_blank">[Paper]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 百度AI智能车 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_AI_smart_car_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Self-Driving Vehicle</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Intelligent Vehicle Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        &nbsp;&nbsp;
        <strong>Sponsor</strong>
        <em><a href="https://www.baidu.com/" target="_blank">Baidu</a></em>
        <br>
        <!--  -->
        <p>Vehicle autonomous driving according to different traffic signs. In addition, based on the target detection algorithm YoloV4-Tiny, the deployment of deep learning algorithms on an embedded development board is realized and guarantees the safe form of the vehicle in the lane.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Detection</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_AI_smart_car_vedio.mp4" target="_blank">[Video]</a>
          <a href="https://ouyaming.github.io/files/project_AI_smart_car_pdf.pdf" target="_blank">[Report]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- LKA -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_LKA_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Lane Keeping Assist (LKA) Control Based on the LQR Controller</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>China ICV Algorithms Challenge</em>
        <br>
        <strong>Award</strong> <em>First Prize</em>
        &nbsp;&nbsp;
        <strong>Sponsor</strong>
        <em><a href="https://www.china-icv.cn/" target="_blank">China-ICV</a></em>
        <br>
        <p>This is about lateral control technology in autonomous driving. Our algorithm enables lateral lane keeping and speed keeping for cars in different scenarios.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">LQR Control</span>
          &nbsp;&nbsp;
          <br>
          &nbsp;&nbsp;
          <br>
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_LKA_vedio.mp4" target="_blank">[Video]</a>
          <a href="https://ouyaming.github.io/files/project_LKA_pdf.pdf" target="_blank">[Report]</a>
          <a href="https://github.com/Zhihaibi/Lateral_control" target="_blank">[Code]</a>        
        </p>
      </td>
    </tr>
  </tbody>
</table>
<head>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</head>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 电赛：动态无线节能充电小车 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 2s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/electronic_design/1.png" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/electronic_design/2.jpg" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Dynamic Wireless Energy-saving Charging Vehicle</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This work is based on TI Msp430F5529 to form a dynamic wireless energy-saving charging cart system. </p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Dynamic Charging</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PID Controller</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/files/project_electronic_design_pdf.pdf" target="_blank">[Report]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 旋转倒立摆 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_secondary_rotary_inverted_pendulum_system_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Rotary Inverted Pendulum System</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This is one of the training programs for electronic design competitions. Through the coordination of stepper motors and angle sensors, and based on a serial PID control algorithm, the system can initiate and maintain an inverted pendulum state. What an interesting experiment!</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Inverted Pendulum</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PID Controller</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_secondary_rotary_inverted_pendulum_system_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 无线动态充电循迹小车 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_wireless_dynamic_charging_tracking_smart_car_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Wireless Dynamic Charging Tracking Smart Car</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This is one of the training programs for electronic design competitions. The smart car realizes dynamic charging during movement through a wireless charging module and has the ability to track the rapid movement of wire lines.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Dynamic Charging</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_wireless_dynamic_charging_tracking_smart_car_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 双线悬挂系统 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_dual_wire_suspension_control_system_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Dual Wire Drive Control System</papertitle>
        </a >
        <br>
        <strong>Competition</strong> <em>National College Students Electronic Design Competition</em>
        <br>
        <strong>Award</strong> <em>National Second Prize</em>
        <br>
        <p>This is one of the training programs for electronic design competitions. The system's driving unit consists of two soft thin strings. The movement in the 2D plane is achieved by controlling the extension and retraction of the two strings independently using stepper motors, allowing the system to draw patterns such as hearts.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Wire Drive</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PID Controller</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_dual_wire_suspension_control_system_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- Turtlebot SLAM -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_turtlebot_slam_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Multi-point Cruise Turtlebot Robot</papertitle>
        </a >
        <p>By deploying the cartographer 2D laser SLAM algorithm on the turtlebot robot, combined with an A* navigation algorithm and a PID motion control algorithm. The robot can realize multi-point cruise operations.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">SLAM</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Navigation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_turtlebot_slam_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 五子棋 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_robotarm_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Human-machine Game of Gomoku with ABB 6-Axis Robotic Arm</papertitle>
        </a >
        <p>Using the RGBD camera (on the hand) to identify gomoku, planning with the robot arm to complete the human-computer game.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Human-machine Game</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Hand-eye Calibration</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_robotarm_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 行李搬运机器人 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_baggage_handling robot_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Luggage Recognition Interactive Robot</papertitle>
        </a >
        <p> Identify the luggage bag and its owner, take the luggage and follow the owner.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Human-robot Interaction</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_baggage_handling robot_vedio.mp4" target="_blank">[Video]</a>
          <a href="https://github.com/OuYaMing/Curriculum-Baggage-Handling-Robot" target="_blank">[Code]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 超市分拣机器人 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <img src="https://ouyaming.github.io/vedio/project_supermarket_automatic_sorting_robot_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Webots Simulation: Supermarket Automatic Sorting Robot</papertitle>
        </a >
        <p> This is the working scenario of a supermarket sorting mobile robot built in the Webots simulation environment. The robot can identify specific items and place them on the corresponding supermarket shelves.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">PathPlanning</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Webots Simulation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_supermarket_automatic_sorting_robot_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- Webots无人驾驶 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_driverless_simulation_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Webots Simulation: Autonomous Driving</papertitle>
        </a >
        <p> This is a self-driving highway simulation system built in the Webots simulation environment. With the obstacle detection algorithm, obstacle avoidance strategy and road tracking control algorithm, the car can safely avoid other obstacles and move forward at a high speed.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Obstacle Avoidance</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Webots Simulation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_driverless_simulation_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 衣物分拣系统 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
          <img src="https://ouyaming.github.io/vedio/project_automatic_clothes_sorting_system_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Clothes Automatic Sorting System</papertitle>
        </a >
        <p>Sorting clothes into different containers according to the color using robot arms.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Detection</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Matlab Simulation</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_automatic_clothes_sorting_system_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 树莓派智能车 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
         <img src="https://ouyaming.github.io/vedio/project_raspberry_pi_smart _car_gif.gif" alt="clean-usnob" width="500" height="300">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Raspberry Pi Smart Car</papertitle>
        </a >
        <p> The main control board of the smart car is a Raspberry Pi 2B+, which uses a camera to identify the red lane lines and track them, and identifies crosswalks to slow down and simulate daily traffic road scenes.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Detection</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Autonomous Driving</span>
          &nbsp;&nbsp;
          <strong>Source</strong>
          <a href="https://ouyaming.github.io/vedio/project_raspberry_pi_smart _car_vedio.mp4" target="_blank">[Video]</a>
        </p>
      </td>
    </tr>
  </tbody>
</table>
<head>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</head>
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: 11.5pt;"> <!-- 餐盘分割 -->
  <tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;border:none;">
        <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel" data-interval="2000"><!-- 1s -->
          <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
          </ol>
          <div class="carousel-inner">
            <div class="carousel-item active">
              <img src="https://ouyaming.github.io/images/Plate_detection/1.gif" class="d-block w-100" alt="Image 1" style="width:600px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/Plate_detection/2.png" class="d-block w-100" alt="Image 2" style="width:500px; height:200px;">
            </div>
            <div class="carousel-item">
              <img src="https://ouyaming.github.io/images/Plate_detection/3.jpg" class="d-block w-100" alt="Image 3" style="width:500px; height:200px;">
            </div>
          </div>
          <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
          </a>
          <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
          </a>
        </div>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle;border:none;">
        <a href="https://ouyaming.github.io/projects/" target="_blank">
          <papertitle>Plate detection through image processing</papertitle>
        </a >
        <p>Image processing techniques were used to extract the location of the dinner plate in the picture, thus assisting the robot to complete the automatic meal-punching operation.</p >
        <p>
          <strong>Tags</strong>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Image Processing</span>
          <span style="background-color: #f0f0f0; padding: 3px 8px; border-radius: 5px; margin-right: 5px;">Target Segmentation</span>
        </p>
      </td>
    </tr>
  </tbody>
</table>

&nbsp;  
&nbsp;  
<table style="width:100%;max-width:601px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=FrEzGBBnkb2X2rV9OFHx8YYKNq1Th4qkAMalbwI5cTg"></script>
</tbody></table>


